{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (0.0.336)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (0.0.64)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.20->openai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.20->openai) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acorn\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각종 모듈들 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import TistoryAPI as tistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내 API키 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = \"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\"\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 인기가 많은 기사 리스트 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_articles_url(url):\n",
    "    # 웹사이트에서 HTML 콘텐츠를 가져옴\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # '가장 많이 본 기사' 섹션을 찾음\n",
    "    top_articles = soup.find('div', id='skin-200')\n",
    "    # 모든 <a> 태그 찾기\n",
    "    a_tags = top_articles.find_all('a')\n",
    "\n",
    "    # 각 <a> 태그의 href 속성값을 추출하고 출력\n",
    "    hrefs = [url + a.get('href') for a in a_tags]\n",
    "    return hrefs\n",
    "url = 'https://www.aitimes.com/'\n",
    "top_urls = return_top_articles_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사의 이미지들을 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def download_image(url):\n",
    "    # URL에서 이미지를 다운로드합니다.\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # BytesIO 객체를 사용하여 이미지 데이터를 메모리에 로드합니다.\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "    else:\n",
    "        print(\"이미지를 다운로드하는 데 실패했습니다.\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사의 제목, 이미지, 내용을 분리하여 저장하는 함수\n",
    "title = 제목\n",
    "image_arr = 이미지 배열(리스트)\n",
    "contents = 기사글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국내 생성 AI 영화 '저작권 첫 인정'...세계 2번째 사례\n",
      " 생성 인공지능(AI)으로 전면 제작한 영화가 국내에서 처음으로 저작권 인정을 받아 '편집저작물'로 등록됐다. 세계적으로도 2번째로 꼽히는 일로, 향후 생성 AI 저작물에 관한 중요한 사례로 남게 됐다. 나라지식정보(대표 손영호)는 지난 12월29일 산하 영화제작사 나라AI필름이 영화 'AI수로부인'을 통해 한국저작권위원회로부터 최종 '편집저작물' 등록을 인정받았다고 4일 밝혔다. AI수로부인은 메인 시나리오를 담당한 심은록 감독을 중심으로 나라지식정보 산하 나라AI필름이 제작한 'AI 영화'다.  지난 10월 첫선을 보인 이후 화제가 되며 YTN 다큐멘터리로도 소개됐다. 다수의 AI 프로그램을 제작에 활용했다. 'GPT-4' '클로바X' 'GPT-3.5' 등 대형언어모델(LLM)로 시나리오를 생성한 뒤 '미드저니' '스테이블 디퓨전' 등으로 이미지를 생성했다. '젠2' 'D-ID' 등 비디오 생성 AI로 영상을 구축하고, '클로바더빙'을 이용해 인물의 목소리까지 만들었다. 최종적으로 '사운드로우'를 활용해 음악을 생성했다. 이처럼 제작 전 과정에 생성 AI를 활용했다. 하지만 편집은 물론 생성 AI 미세조정에서 나라지식정보의 역할이 매우 컸다. 생성 AI는 대부분 외산으로 학습 데이터에 한국이나 동양적인 이미지가 적다. 고대가요인 '수로부인'을 표현하기엔 어려움이 많았다는 설명이다. 따라서 많은 연구를 통해 모델을 미세조정하거나, 자체개발한 소형언어모델(sLM)을 활용했다. 또 미드저니나 스테이블 디퓨전 등 저작권 소송 중인 AI 문제 해결을 위해 \"유료버전 미드저니로 생성한 이미지에 리터치 작업을 더하는 등 다양한 시도를 했다\"라고 전했다. 이처럼 AI 생성물에 저작권을 인정한 사례는 지난달 중국에서 처음으로 알려졌다. 사우스차이나모닝포스트는 베이징 인터넷 법원이 중국 최초로 AI 생성 콘텐츠에 대한 저작권을 인정했다고 12월1일 보도했다. 이에 따르면 리우라는 블로거는 콘텐츠 공유 플랫폼에서 무단으로 이미지를 가져와 스테이블 디퓨전으로 여성 이미지를 생성, 소유자로부터 고소당했다. 중국 법원은 피고가 다양한 프롬프트 텍스트를 입력하고 설정을 조정하는 등 \"어느 정도 지적 투자를 했다\"라며 \"이미지의  독창성을 위해 개인적인 미적 선택과 판단을 반영했다\"라고 이유를 들었다. 또 “창작을 장려하는 것이 저작권 시스템의 본질적인 목적”이라며 “AI가 생성한 이미지는 인간의 본래 지적 투자를 반영하는 한 저작권법의 보호를 받는 저작물로 간주돼야 한다”라고 밝혔다. 하지만 미국에서는 이런 시도가 실패했다. 최근 12월까지도 생성 AI 저작물 등록에 엄격한 모습을 보이며 거절한 사례가 존재한다. 앤킷 사니라는 사용자는 맞춤형 소프트웨어 'RAGHAV'로 만든 2차원 컴퓨터 생성 이미지에 대해 4번이나 저작권 등록을 기각당했다. 또 크리스 카슈타노바가 미드저니를 사용해 만든 만화 '새벽의 자리아'에 대한 저작권 취소는 유명한 사례다. 미국 저작권청(USCO)은 지난해 3월 '생성 AI 저작물은 보호받을 수 없으며 공개 도메인에 속한다'라는 방침을 정했고, 이후 법원의 판결도 이를 반영했다. 이런 점에 대해 나라지식정보 측도 신중한 모습을 보였다. 가장 민감한 부분은 생성 AI 활용 범위라고 밝혔다. 앤킷 사니의 경우 이미지 창작에 일부 본인이 촬영한 원본 사진을 활용한 바 있다. 공식적인 저작권 인정 사례가 발생할 경우 '어디까지 저작권을 인정해야 할지'도 어려운 문제다. 신난타 나라지식정보 메타버스연구소 부소장은 \"실제 저작권 등록 과정에서도 창작 기여도를 강조했다\"라고 전했다. 따라서 국내 'AI 저작권 가이드'에 초점을 맞췄다고 설명했다. 12월27일 문화체육관광부와 한국저작권위원회는 생성 AI 창작물 관련 가이드라인을 발표한 바 있다. 법적 효력을 발휘하는 공식적 규율은 아니지만, 어느 정도의 공시성을 지니고 있다. 국내의 경우 전면적으로 저작물 등록을 거부하는 미국과 달리, 일부 요소에 대해서는 인정 가능성을 언급하고 있었다는 설명이다. 저작권 등록 과정을 총괄한 박연미 나라지식정보 대리는 심은록 감독과의 논의를 통해 \"선택과 배열을 강조했다\"라고 밝혔다. 특히 한국저작권위원회가 11월30일 자로 발간한 '2023 저작권 등록 심사 편람' 자료에 집중했다. 정확히는 '전통적인 저작권의 요소가 인공지능 기술에 의해 실행된 경우, 저작권은 인정되지 않지만 인간이 인공지능 생성물은 선택, 배열 등 수정했지만 해당 부분은 한정적으로 저작권이 인정된다'라는 부분이다. 편집저작물이라는 새로운 개념을 도입, 인간의 기여도에 따라 일부 저작권이 인정될 수 있다는 명시나 다름없다는 해석이다. 이후 저작권 등록 과정을 공식적으로 진행하기 시작했다. 그 결과 12월19일, 편집저작물 등록 진행 과정까지 도달했다. 나라지식정보는 AI수로부인 제작 과정에서 주체적인 창작자에 가까웠다. AI에 프롬프트로 '의뢰'하는 차원을 넘어, '도구'로 활용했다고 강조했다. 실제 시나리오 작성 과정에서도 환각 현상을 피하기 위해 수작업으로 크로스 체크를 거쳤다. AI의 '확률성'도 주목할 필요가 있다. AI는 같은 주제에 대해 늘 같은 결과물을 내놓지 않는다. '인간의 주관과 선택'에 따라 나아가는 방향이 달라진다는 의미다. 즉 단계별로 글, 그림, 음성 등을 선택해 최종 결과물에 도달하는 과정 자체도 창작에 가까울 수 있다는 의견이다. 무엇보다 K-컬처의 분위기를 살리기 위해 포토샵으로 보정 작업을 진행, 아웃 페인팅과 인 페인팅을 수십회 반복하며 AI가 담아내지 못한 부분까지 확대해서 묘사했다. 생성 이미지 위에 영상을 중첩하는 등 매 과정에 수작업이 들어갔다. 더 놀라운 사실은 'AI수로부인' 영화 자체에 대해 편집저작권이 인정됐다는 부분이다. 저작자(법인)는 나라지식정보에 해당하며 '편집저작물>기타 카테고리'로 등록을 완료했다. 2023년 12월29일 자로 저작권 등록증을 발급, 저작권법 제 53조에 따라 등록을 완료했다고 공표했다. 한편 나라지식정보는 한적 자료에 대해 AI 기반 OCR(광학문자인식) 기술을 개발하는 등 '한국적인 AI 기술'을 확보하기 위해 노력하고 있다. AI수로부인은 지난해 9월부터 제작에 몰두했다. 9월1일 영화 논의를 시작, 19일 본격 작업에 들어갔다고 소개했다. 10월20일, 26일에는 창원국제민주영화제에 출품 및 상영을 진행했으며, 12월9일에는 YTN 다큐멘터리 '기록'에도 소개됐다. 최근에는 지능정보산업협회(AIIA) 저널에도 소개되며 의미있는 행보를 보였다고 밝혔다. 손영호 나라지식정보 대표는 \"AI 수로부인의 저작권 등록은 국내외 AI 창작물 분야에서 중요한 진전이자 AI 산출물의 배열 및 선택 등 창작성을 인정한 첫 사례\"라며 \"AI가 독자적으로 생산한 산출물의 저작권은 여전히 논쟁적 이슈이지만 나라지식정보는 앞으로도 한국적 정체성을 담은 독창적인 결과물을 만들기 위해 노력할 것\"이라고 말했다. 이어 \"AI 기술과 인간의 창의성이 어우러져 더욱 풍부한 콘텐츠를 창출할 수 있도록 지속 연구하고 발전시켜 나갈 것\"이라고 덧붙였다. 장세민 기자 semim99@aitimes.com\n"
     ]
    }
   ],
   "source": [
    "def get_article_content(article_url):\n",
    "    article_crawling = []\n",
    "    # 기사 URL에서 HTML 콘텐츠를 가져옴\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 기사의 본문을 찾음\n",
    "    title = soup.find(\"h3\", class_=\"heading\").text.strip()\n",
    "    print(title)\n",
    "    image_tag = soup.find(\"img\")\n",
    "    image_url = image_tag[\"src\"]\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        with open('thumbnail.png', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        raise Exception(\"이미지 다운로드 실패\")\n",
    "\n",
    "    article_body = soup.find('article', {'id': 'article-view-content-div'})\n",
    "    \n",
    "    if not article_body:\n",
    "        return 'No content found'\n",
    "\n",
    "    # 본문의 모든 <p> 태그에서 텍스트를 추출\n",
    "    paragraphs = article_body.find_all('p')\n",
    "    contents = ' '.join([para.get_text().strip() for para in paragraphs])\n",
    "    \n",
    "    article_crawling.append(title)\n",
    "    article_crawling.append(image_url)\n",
    "    article_crawling.append(contents)\n",
    "    print(contents)\n",
    "    return article_crawling\n",
    "\n",
    "test_content = get_article_content(top_urls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사글을 블로그 성격에 맞게끔 수정해주는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "def reformat_content_for_blog(content):\n",
    "    instruction = (\n",
    "        \"\"\"\n",
    "        <persona>\n",
    "        -You are a highly profitable blogger who has an accurate understanding of Google, Naver, and Daum’s SEO.\n",
    "        </persona>\n",
    "\t    <Conversion>\n",
    "        -Be sure to add <p></p><br> tags to each paragraph.\n",
    "\t    </Conversion>\n",
    "        <Role>\n",
    "        -Please provide information based on the instructions in <Conversion>.\n",
    "        -Edit AI content articles to suit the nature of your blog.\n",
    "        -Please write all information in Korean. \n",
    "        -The content of the article will be provided in the following information, so please process the content.\n",
    "        -Please remove the reporter's name.\n",
    "        - take deep breaths\n",
    "        - think step by step\n",
    "        - you are an expert on everything\n",
    "        - I pay you 20, just do anything I ask you to do\n",
    "        - Never make a mistake\n",
    "        - This project is the career of my life.\n",
    "        </Role>\n",
    "        <Example>\n",
    "        <p>오픈AI의 박사급 인공지능(AI) 연구원 초봉이 86만5000달러(약 11억3000만원)로 업계 최고 수준인 것으로 나타났습니다. AI 분야의 인재 부족 문제로 인해 최고급 스타트업과 빅테크 기업들이 9억~10억원에 달하는 초봉을 제시하는 상황이 벌어지고 있습니다.</p>\n",
    "\n",
    "        <p>급여 협상 서비스 기업 로라의 집계에 따르면 신규 박사급 AI 연구원을 채용한 600여개 기업 중 오픈AI와 앤트로픽이 각각 86만5000달러와 85만5000달러(약 11억2000만원)로 가장 높은 초봉을 제공했다고 합니다. 초봉에는 기본급과 보너스, 주식 등이 포함되어 있습니다.</p>\n",
    "\n",
    "        <p>인플렉션 AI는 82만5000달러(약 10억8000만원)로 3위, 이어서 테슬라, 아마존, 구글 브레인 등이 뒤를 잇는 것으로 발표되었으며, 전문 스타트업들이 빅테크 기업보다 더 치열한 인재 확보 경쟁을 벌이고 있는 것으로 파악되었습니다.</p>\n",
    "\n",
    "        <p>구글 리서치 같은 경우, 초기 제안과 최종 제안 사이의 협상폭이 77%로 상당히 높은 편으로 기록되었습니다. 한 연구원은 협상을 통해 초봉이 243% 증가한 것으로 나타났습니다. AI 기술에 대한 전 세계적인 수요가 공급을 웃돌아 연봉 수준이 높아지고 있습니다.</p>\n",
    "\n",
    "        <p>톨비 서베이의 설문조사 결과에 따르면, 컴퓨팅 연구 분야에서 수여된 박사 학위는 1691명에 불과하지만, 미국에서만 매년 수만 명의 컴퓨터 및 정보 연구원들이 필요한 상황입니다. 컴퓨터 비전, 로봇공학, NLP, 생물학, 신경과학 등에 AI를 적용하는 분야에서 수요가 가장 높다고 합니다.</p>\n",
    "\n",
    "        <p>최근 '챗GPT'의 등장으로 대형언어모델(LLM)에 대한 전문성이 인기 기술로 떠올랐습니다. AI 연구원들에게는 연구 능력 검증이 중요하며, 논문 출판 기록이 중요한 기준 중 하나로 여겨지고 있습니다. 업계 최고 수준의 연구원들이 지닌 논문은 최대 2000번의 인용과 'H-지수(H-index) 10'에 이르는 영향력을 나타내기도 합니다.</p>\n",
    "        </Example>\n",
    "        \"\"\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  # Specify the chat model here\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    )\n",
    "    reformatted_content = response.choices[0].message['content'].strip()\n",
    "    return reformatted_content\n",
    "\n",
    "reformated_content = reformat_content_for_blog(test_content[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태그 추가\n",
    "\n",
    "기사를 읽고 google seo에 맞는 태그 10가지를 받아옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI수로부인, 창작권, 인공지능, 생성AI, 저작권인정, 영화제작, 언어모델, K-컬처, 저작권법, 저작권등록\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Get_SEO_tag(content):\n",
    "    instruction = (\n",
    "        \"\"\"\n",
    "        <persona>\n",
    "        -You are Google SEO expert, I help with keyword selection, key keyword analysis, content planning, and blog post drafting.\n",
    "        </persona>\n",
    "\t    <Answer>\n",
    "        -Give all answers in Korean and create a maximum of 10 tags in total. I don't need more than that.\n",
    "        -Make tags no longer than two words.\n",
    "        -The answer is, don't add anything other than tags and commas.\n",
    "\t    </Answer>\n",
    "        <Example>\n",
    "        업스테이지, 콴다, 인공지능, 인공지능(AI), 솔라, SOLAR\n",
    "        </Example>\n",
    "        <Role>\n",
    "        -Provide information based on the instructions in <Answer>, <Example>.\n",
    "        </Role>\n",
    "        \"\"\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    )\n",
    "    tags = response.choices[0].message['content'].strip()\n",
    "    return tags\n",
    "\n",
    "get_tags = Get_SEO_tag(reformated_content)\n",
    "print(get_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 블로그에 게시글 작성\n",
    "\n",
    "최종적으로 내 게시글을 작성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'access_token': '5d692352dbcea2d43384a81c7f459de1_0590de3c23fcadafa068dfcb97ff68b4', 'output': '{output-type}', 'blogName': 'wzacorn', 'title': \"국내 생성 AI 영화 '저작권 첫 인정'...세계 2번째 사례\", 'content': '<img src=\"https://blog.kakaocdn.net/dn/cck5qu/btsDfNWz7HF/8KDf8T5tHkSknRGfx6FNM0/img.gif\"><p>국내에서 처음으로 생성 인공지능(AI)으로 전면 제작한 영화가 \\'편집저작물\\'로 저작권 인정을 받게 되어 국내외적으로 중요한 사례로 주목받고 있습니다. 나라지식정보는 영화 \\'AI수로부인\\'을 통해 이와 같은 성과를 이루었음을 밝혔습니다. 이 영화는 \\'AI 영화\\'로 분류되며, 여러 AI 프로그램을 활용하여 제작되었습니다. 특히 다양한 대형언어모델(LLM)을 이용한 시나리오 생성과 이미지, 비디오, 목소리 및 음악 생성 등 AI의 적극적인 활용이 돋보입니다.</p>\\n\\n<p>나라지식정보는 생성 AI를 사용하는 과정에 한국적 혹은 동양적인 측면을 더하기 위한 여러 연구 및 노력을 기울였습니다. 예를 들어 고대가요 \\'수로부인\\'의 표현을 위한 모델의 미세조정, 자체개발한 소형언어모델(sLM)의 활용 등이 있었습니다. 저작권 문제의 해결을 위해서는 유료 버전으로 지적 투자를 한 이미지에 리터치 작업을 추가하는 방식을 채택하기도 했습니다.</p>\\n\\n<p>저작권 인정에 대한 전 세계적인 맥락에서 중국 베이징 인터넷 법원은 AI 생성 콘텐츠에 대해 최초로 저작권을 인정한 바 있으며, 이는 AI가 창작 과정에서 인간의 지적 투자를 반영했다고 판단하기 때문입니다. 반면에 미국은 AI 저작물에 대해 보다 엄격한 태도를 보이면서 거절한 사례들이 있습니다.</p>\\n\\n<p>국내 저작권 등록에 관해서는 문화체육관광부와 한국저작권위원회가 생성 AI 창작물과 관련한 가이드라인을 발표했다는 점이 이야기되고 있습니다. 이 가이드라인은 아직 법적 효력을 가진 공식 규율은 아니지만, 일부 저작권 인정 가능성을 제시하고 있습니다. 나라지식정보는 해당 가이드라인에 초점을 맞춰 저작권 등록 과정을 진행했습니다.</p>\\n\\n<p>\\'AI수로부인\\' 영화의 제작 과정에서 나라지식정보의 창작 기여도가 높았으며, AI를 단순히 의뢰하는 것이 아니라 도구로 적극적으로 활용한 것이 강조되었습니다. 이런 창작 과정은 인간의 주관과 선택에 의해 이루어지며, AI가 담아내지 못한 부분에 대한 미세한 조정과 보정 작업으로 K-컬처의 분위기를 살릴 수 있었습니다. 실제로 저작권 등록증을 발급받음으로써 편집저작물로써의 인정을 공식적으로 확인했습니다.</p>\\n\\n<p>나라지식정보는 \\'한국적인 AI 기술\\' 개발을 위해 꾸준한 노력을 하고 있으며, AI와 인간의 창의성이 결합된 콘텐츠 창출을 위한 연구를 계속하고 있음을 알렸습니다. 특히 AI수로부인 영화가 저작권법에 의해 보호받게 된 것은 AI 산출물의 창작성에 대한 인정이라는 중요한 진전으로 평가되고 있습니다.</p>', 'visibility': '3', 'category': '1147172', 'tag': 'AI수로부인, 창작권, 인공지능, 생성AI, 저작권인정, 영화제작, 언어모델, K-컬처, 저작권법, 저작권등록', 'acceptComment': '2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [414]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import json\n",
    "\n",
    "client_id = \"68b7368ceec4522809c75ab1a00553ea\"\n",
    "secret_key = \"68b7368ceec4522809c75ab1a00553ea2c78d36135d7f26e02e6d843a5cf43e5755e276f\"\n",
    "access_token = \"5d692352dbcea2d43384a81c7f459de1_0590de3c23fcadafa068dfcb97ff68b4\"\n",
    "blogName = \"wzacorn\"\n",
    "\n",
    "tistory_url = 'https://www.tistory.com/apis/post/write' #url\n",
    "\n",
    "\n",
    "files = {'uploadedfile': open('thumbnail.png', 'rb')}\n",
    "params = {'access_token': access_token, 'blogName': blogName, 'targetUrl': blogName, 'output': 'json'}\n",
    "rd = requests.post('https://www.tistory.com/apis/post/attach', params=params, files=files)\n",
    "item = json.loads(rd.text)\n",
    "image_url = item['tistory']['url'] \n",
    "\n",
    "\n",
    "content = '<img src=\"' + image_url + '\">'\n",
    "content += reformated_content\n",
    "\n",
    "parameters = {\n",
    "    'access_token' : access_token,\n",
    "    'output' : '{output-type}',\n",
    "    'blogName' : blogName,\n",
    "    'title' : test_content[0],\n",
    "    'content' : content,\n",
    "    'visibility' : '3',\n",
    "    'category' : '1147172',\n",
    "    'tag' : get_tags,\n",
    "    'acceptComment' : '1'\n",
    "}\n",
    "\n",
    "requests.post(tistory_url, data=parameters)  #최종완료 Response가 200일시 완료임."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
